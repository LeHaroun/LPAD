{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cc4f3d",
   "metadata": {
    "id": "1bc56579"
   },
   "source": [
    "# # License Plate Detection and OCR\n",
    "This notebook demonstrates a workflow for detecting license plates in images and extracting text from them using YOLO models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37094a7",
   "metadata": {
    "collapsed": true,
    "id": "f37094a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (5.1.2)\n",
      "Requirement already satisfied: fastapi in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.104.1)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.7.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.7.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (3.7.2)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: packaging in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (2.0.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (2.5.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer[all]<1.0,>=0.9 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio) (0.24.0.post1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio-client==0.7.0->gradio) (2023.4.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from gradio-client==0.7.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.14.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from requests~=2.0->gradio) (2023.7.22)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (8.0.4)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from fastapi->gradio) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from fastapi->gradio) (0.27.0)\n",
      "Requirement already satisfied: httpcore in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (9.4.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\dr ahmed haroun\\anaconda3\\lib\\site-packages (from pytesseract) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "!pip install Pillow pytesseract\n",
    "!pip install opencv-contrib-python==4.5.1.48\n",
    "!pip install --upgrade arabic-reshaper\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from google.colab import files\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# normal CPU T\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f3cfe",
   "metadata": {
    "id": "8a6f3cfe"
   },
   "source": [
    "\n",
    "## Model Loading\n",
    "Here we define classes for plate detection and OCR and load the pre-trained models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1868717",
   "metadata": {
    "collapsed": true,
    "id": "e1868717"
   },
   "outputs": [],
   "source": [
    "class PlateDetector:\n",
    "    def load_model(self, weight_path: str, cfg_path: str):\n",
    "        self.net = cv2.dnn.readNet(weight_path, cfg_path)\n",
    "        with open(\"classes-detection.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "        self.layers_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layers_names[i[0]-1] for i in self.net.getUnconnectedOutLayers()]\n",
    "\n",
    "    def load_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        height, width, channels = img.shape\n",
    "        return img, height, width, channels\n",
    "\n",
    "    def detect_plates(self, img):\n",
    "        blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outputs = self.net.forward(self.output_layers)\n",
    "        return blob, outputs\n",
    "\n",
    "    def get_boxes(self, outputs, width, height, threshold=0.3):\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        for output in outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > threshold:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "        return boxes, confidences, class_ids\n",
    "\n",
    "    def draw_labels(self, boxes, confidences, class_ids, img):\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        plats = []\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(self.classes[class_ids[i]])\n",
    "                color_green = (0, 255, 0)\n",
    "                crop_img = img[y:y+h, x:x+w]\n",
    "                try:\n",
    "                    crop_resized = cv2.resize(crop_img, dsize=(470, 110))\n",
    "                    plats.append(crop_resized)\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), color_green, 8)\n",
    "                    confidence = round(confidences[i], 3) * 100\n",
    "                    cv2.putText(img, str(confidence) + \"%\", (x + 20, y - 20), font, 12, (0, 255, 0), 6)\n",
    "                except cv2.error as err:\n",
    "                    print(err)\n",
    "\n",
    "        return img,plats\n",
    "\n",
    "class PlateReader:\n",
    "    def load_model(self, weight_path: str, cfg_path: str):\n",
    "        self.net = cv2.dnn.readNet(weight_path, cfg_path)\n",
    "        with open(\"classes-ocr.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "        self.layers_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layers_names[i[0]-1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.colors = np.random.uniform(0, 255, size=(len(self.classes), 3))\n",
    "\n",
    "    def load_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        height, width, channels = img.shape\n",
    "        return img, height, width, channels\n",
    "\n",
    "    def read_plate(self, img):\n",
    "        blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outputs = self.net.forward(self.output_layers)\n",
    "        return blob, outputs\n",
    "\n",
    "    def get_boxes(self, outputs, width, height, threshold=0.3):\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "        for output in outputs:\n",
    "            for detect in output:\n",
    "                scores = detect[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > threshold:\n",
    "                    center_x = int(detect[0] * width)\n",
    "                    center_y = int(detect[1] * height)\n",
    "                    w = int(detect[2] * width)\n",
    "                    h = int(detect[3] * height)\n",
    "                    x = int(center_x - w/2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        return boxes, confidences, class_ids\n",
    "\n",
    "    def draw_labels(self, boxes, confidences, class_ids, img):\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.1)\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        c = 0\n",
    "        characters = []\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(self.classes[class_ids[i]])\n",
    "                color = self.colors[i % len(self.colors)]\n",
    "                cv2.rectangle(img, (x,y), (x+w, y+h), color, 3)\n",
    "                confidence = round(confidences[i], 3) * 100\n",
    "                cv2.putText(img, str(confidence) + \"%\", (x, y - 6), font, 1, color, 2)\n",
    "                characters.append((label, x))\n",
    "        characters.sort(key=lambda x:x[1])\n",
    "        plate = \"\"\n",
    "        for l in characters:\n",
    "            plate += l[0]\n",
    "        chg = 0\n",
    "        for i in range(len(plate)):\n",
    "            if plate[i] in ['b', 'h', 'd', 'a']:\n",
    "                if plate[i-1] == 'w':\n",
    "                    ar = i-1\n",
    "                    chg = 2\n",
    "                elif plate[i-1] == 'c':\n",
    "                    ar = i - 1\n",
    "                    chg = 3\n",
    "                else:\n",
    "                    ar = i\n",
    "                    chg = 1\n",
    "\n",
    "        if chg == 1:\n",
    "            plate = plate[:ar] + ' | ' + str(self.arabic_chars(ord(plate[ar])), encoding=\"utf-8\") + ' | ' + plate[ar+1:]\n",
    "        if chg == 2:\n",
    "            index = 0\n",
    "            for i in range(3):\n",
    "                index = index + plate[ar+i]\n",
    "            plate = plate[:ar] + ' | ' + str(self.arabic_chars(index), encoding=\"utf-8\") + ' | ' + plate[ar+3:]\n",
    "        if chg == 3:\n",
    "            index = 0\n",
    "            for i in range(2):\n",
    "                index = index + plate[ar+i]\n",
    "            plate = plate[:ar] + ' | ' + str(self.arabic_chars(index), encoding=\"utf-8\") + ' | ' + plate[ar+2:]\n",
    "\n",
    "        return img, plate\n",
    "\n",
    "    def arabic_chars(self, index):\n",
    "        if (index == ord('a')):\n",
    "            return \"أ\".encode(\"utf-8\")\n",
    "\n",
    "        if (index == ord('b')):\n",
    "            return \"ب\".encode(\"utf-8\")\n",
    "\n",
    "        if (index == 2 * ord('w') + ord('a') or index == ord('w')):\n",
    "            return \"و\".encode(\"utf-8\")\n",
    "\n",
    "        if (index == ord('d')):\n",
    "            return \"د\".encode(\"utf-8\")\n",
    "\n",
    "        if (index == ord('h')):\n",
    "            return \"ه\".encode(\"utf-8\")\n",
    "\n",
    "        if (index == ord('c') + ord('h')):\n",
    "            return \"ش\".encode(\"utf-8\")\n",
    "\n",
    "    def tesseract_ocr(self, image, lang=\"eng\", psm=7):\n",
    "        alphanumeric = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "        options = \"-l {} --psm {} -c tessedit_char_whitelist={}\".format(lang, psm, alphanumeric)\n",
    "        return pytesseract.image_to_string(image, config=options)\n",
    "\n",
    "# Load models\n",
    "detector = PlateDetector()\n",
    "detector.load_model('detection/yolov3-detection_final.weights', 'detection/yolov3-detection.cfg')\n",
    "\n",
    "reader = PlateReader()\n",
    "reader.load_model('ocr/yolov3-ocr_final.weights', 'weights/ocr/yolov3-ocr.cfg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5251ae96",
   "metadata": {
    "id": "5251ae96"
   },
   "source": [
    "\n",
    "## Integrated Processing Pipeline\n",
    "This function integrates image loading, detection, and OCR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0b2d14",
   "metadata": {
    "collapsed": true,
    "id": "7e0b2d14"
   },
   "outputs": [],
   "source": [
    "\n",
    "def process_image(image_path):\n",
    "    # Load image\n",
    "    img, height, width, channels = detector.load_image(image_path)\n",
    "\n",
    "    # Detect plates\n",
    "    blob, outputs = detector.detect_plates(img)\n",
    "    boxes, confidences, class_ids = detector.get_boxes(outputs, width, height, threshold=0.3)\n",
    "    plate_img, LpImg = detector.draw_labels(boxes, confidences, class_ids, img)\n",
    "\n",
    "    # Check if any plates were detected\n",
    "    if not LpImg:\n",
    "        return \"No plates detected, Try to change Camera angle or Lighting Conditions\"\n",
    "\n",
    "    # Perform OCR on the first detected plate\n",
    "    ocr_image = LpImg[0]  # assuming the first detected plate\n",
    "    blob, outputs = reader.read_plate(ocr_image)\n",
    "    boxes, confidences, class_ids = reader.get_boxes(outputs, width, height, threshold=0.3)\n",
    "    segmented, plate_text = reader.draw_labels(boxes, confidences, class_ids, ocr_image)\n",
    "\n",
    "    # Return OCR result\n",
    "    return plate_text\n",
    "\n",
    "\n",
    "# Usage usage\n",
    "result = process_image('images/Example1.jpg')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A1jNEemh4EEq",
   "metadata": {
    "id": "A1jNEemh4EEq"
   },
   "source": [
    "# Gradio Interface\n",
    "Upload and test images from local computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W3ehYXEr4P6T",
   "metadata": {
    "collapsed": true,
    "id": "W3ehYXEr4P6T"
   },
   "outputs": [],
   "source": [
    "def gradio_process_image(image):\n",
    "    # Save the image to a temporary file and process it\n",
    "    image_path = '/tmp/uploaded_image.jpg'\n",
    "    image.save(image_path)\n",
    "    return process_image(image_path)\n",
    "\n",
    "# Example images\n",
    "examples = [\n",
    "    'images/Example1.jpg',\n",
    "    'images/Example2.jpg',\n",
    "    'images/Example3.jpg'\n",
    "    # Add paths to more example images\n",
    "]\n",
    "\n",
    "# Create the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_process_image,\n",
    "    inputs=gr.inputs.Image(type=\"file\", label=\"Upload an Image\"),\n",
    "    outputs=\"text\",\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
